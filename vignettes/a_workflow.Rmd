---
title: "Workflow overview"
output: 
  rmarkdown::html_document:
    toc: true 
    toc_depth: 3
    number_sections: false
vignette: >
  %\VignetteIndexEntry{1 - Specifying your model}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
pkgdown:
  as_is: true
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```
## Introduction
**bllFlow** emphasizes a _pre-specified_ approach to analyses. Pre-specified means 
a model is specified prior to examining the relationship between predictors (also 
known as risk factors or features) and the outcome (target). All analyses are logged, 
allowing transparent reporting. 

### The Model Specification Workbook (MSW)
The MSW is a series of XX worksheets -- each a CSV file -- that describe the 
model specification. You can use bllFlow without a MSW but we recommend using 
atleast the `variables` and `variable_details` worksheets. 

- **variables** - Each row in the `variables.csv` file is a variable in your model. 
The columns include variable labels, type, and other information such as which 
variables are transformed (centered, have dummy variables, restrictive cubic 
splines, have interaction terms, etc.).
- **variables_details** - 
- **model description** - 
- **table description** - 

### Step 1 - Pre-specifying your model
The model specifications are recorded within the Model Specification Workbook 
(MSW). Each predictor in your model is a row in the MSW. Included are columns 
for variable labels, data cleaning, variable transformation rules and other 
instructions that can be rountinely-performed (Step 4).

Creating the MSW invovles everyone on your team: analysts, methodologist and
content experts. Trainees will want to review their MSW with their supervisor 
and thesis committee. 

### Step 2 - Describing the study cohort
Research studies tyipically include a "Table 1" that describe the study cohort 
or population. This step creates a CSV file, `aggregated-results`, with the all 
infomation required for Table 1 and also similar descriptive tables and 
codebooks. **bllFlow** follows the [Data Documentation Intitiatve](https://www.ddialliance.org) concept of "one document, many uses."

**bllFlow** steps are sequential, but there is room a small amount if iteration, 
particularly for Step 2. For example, most research reporting guidelines 
recommended a description of the study cohort before any data cleaning -- thereby 
disclosing and communicating data quality (amount of missing data, etc.). It is 
helpful to also describe of your study data after data cleaning, 
and variable transformation (Step 3).

### Step 3 - Data cleaning and variable transformation
Data cleaning and varible transformation is the most time consuming step of 
model development -- and also a step that poorly communicated and difficult 
to reproduce. **bllFlow** strives to reduce the effort required in this 
step as much as possible, while also improving transparency and reproduciblity. 

### Step 4 - Developing a predicitve model
This step is short and breif for **bllFlow**. **bllFlow**
 doesn't contain any functions for actual statistical or machine learning models.
 Rather, **bllFlow** acts more like a wrapper around the model model derivation, 
 by providing help prior to and following actual model development. You bring 
 your own model functions. 
 
 A challenge when using different modelling packages and software programs 
 are different approaches to variable transformation that occurres within model 
 generation. For example, dummy variables are created in different packages 
 during function call and then exported, but using different naming conventions. 
 In **bllFlow**, dummy variables are generated prior to function call.
 
### Step 5 - Reporting the performance of a model
This section generates performance reports for predictive 
algorithms -- and much of this section will not be helpful if are performing 
other types of studies. We add onto popular packages such as Hmisc in three ways. 
First, we modify a few functions for competing risk algorithms, since these 
functions are underdeveloped. Second, **bllFlow** have versions of calibration
 plots and other visualizations. Third, plots are designed to replication on 
 many subgroups, using information from the `aggregated-results` data frame.
 
### Step 6 - Describing a model
**bllFlow** creates a consistent structure for descdribing models. The same as 
other steps, a structured data frame, `model-description` is created to 
facilitate export as a CSV file or other document format. Critically, the model 
description is translated to Predictive Model Modelling Language (PMML) for 
deployment in various settings. PMML can be imported into Tensor Flow deployment 
engines (with future plans for export to Tensor Flow Graph). `model-description`
 is also used for manuscript-ready exhibits.
 
### Reference files - Variable types, labels and metadata
**bllFlow** uses consistent labels and metadata throughout the workflow. 
**bllFlow** metadata is alligned with two documentation initiatives: the 
[Data Documentaiton Initiative (DDI)](https://www.ddialliance.org) and 
[PMML](http://dmg.org). The `variable-metadata` file is a table that identifies 
all variable types used. For example, `mean`  refers to the mean value of an 
exposure. All variable types are defined to ensure consistent, understandable and machine-actionable across software libraries. 

### Helper and utility functions
Miscellaneous functions to support your workflow. For example, we perform 
research in secure data environments using personal health information. These 
data cannot be publicly shared. Instead, we generate fake data that allow us to 
demonstrate the analyses plan and also to validate deployment of the algorithm. 
Utility and helper functions are used to make these data. 